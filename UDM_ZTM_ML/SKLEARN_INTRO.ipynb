{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Typical scikit-learn Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease = pd.read_csv('https://raw.githubusercontent.com/tronghieu2810/MACHINE-LEARNING/main/UDM_ZTM_ML/data/heart-disease.csv')\n",
    "heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart_disease.drop('target', axis=1)\n",
    "y = heart_disease['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict(X_test)\n",
    "print(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test,  y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_preds), '\\n')\n",
    "print(confusion_matrix(y_test, y_preds), '\\n')\n",
    "print(accuracy_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "for i in range(10, 100, 10):\n",
    "    print(f'Trying model with {i} estimators ...')\n",
    "    clf = RandomForestClassifier(n_estimators=i)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f'Model accuracy on test set: {clf.score(X_test, y_test) * 100:.2f}')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open('random_forest_model_1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('random_forest_model_1.pkl', 'rb'))\n",
    "loaded_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Your Data Ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart_disease.drop('target', axis=1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X.shape, X_train.shape, X_test.shape, y.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Data To Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales = pd.read_csv('https://raw.githubusercontent.com/tronghieu2810/MACHINE-LEARNING/main/UDM_ZTM_ML/data/car-sales-extended.csv')\n",
    "car_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(car_sales.dtypes, '\\n')\n",
    "X_col = car_sales.columns\n",
    "print(f'{X_col} - {type(X_col)} - {X_col[1]}')\n",
    "# print(car_sales.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = car_sales.drop('Price', axis=1)\n",
    "y = car_sales['Price']\n",
    "\n",
    "categorical_features = ['Make', 'Colour', 'Doors']\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(  'one_hot',\n",
    "                                    one_hot,\n",
    "                                    categorical_features)],\n",
    "                                remainder='passthrough')\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.head(), '\\n')\n",
    "print(pd.DataFrame(transformed_X).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(car_sales[['Make', 'Colour', 'Doors']])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X,\n",
    "                                                    y, \n",
    "                                                    test_size=0.2)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values With Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing = pd.read_csv('https://raw.githubusercontent.com/tronghieu2810/MACHINE-LEARNING/main/UDM_ZTM_ML/data/car-sales-extended-missing-data.csv')\n",
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing['Make']         .fillna('missing', inplace=True)\n",
    "car_sales_missing['Colour']       .fillna('missing', inplace=True)\n",
    "car_sales_missing['Odometer (KM)'].fillna(  car_sales_missing['Odometer (KM)'].mean(), \n",
    "                                            inplace=True)\n",
    "car_sales_missing['Doors']        .fillna(4, inplace=True)\n",
    "\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.dropna(inplace=True)\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = car_sales_missing.drop('Price', axis=1)\n",
    "y = car_sales_missing['Price']\n",
    "\n",
    "categorical_features = ['Make', 'Colour', 'Doors']\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(  'one_hot',\n",
    "                                    one_hot,\n",
    "                                    categorical_features)],\n",
    "                                remainder='passthrough')\n",
    "\n",
    "transformed_X = transformer.fit_transform(car_sales_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values With Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing = pd.read_csv('https://raw.githubusercontent.com/tronghieu2810/MACHINE-LEARNING/main/UDM_ZTM_ML/data/car-sales-extended-missing-data.csv')\n",
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing.dropna(subset=['Price'], inplace=True)\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = car_sales_missing.drop('Price', axis=1)\n",
    "y = car_sales_missing['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_imputer  = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "door_imputer = SimpleImputer(strategy='constant', fill_value=4)\n",
    "num_imputer  = SimpleImputer(strategy='mean')\n",
    "\n",
    "cat_features = ['Make', 'Colour']\n",
    "door_feature = ['Doors']\n",
    "num_features = ['Odometer (KM)']\n",
    "\n",
    "imputer = ColumnTransformer([\n",
    "    ('cat_imputer',  cat_imputer,  cat_features),\n",
    "    ('door_imputer', door_imputer, door_feature),\n",
    "    ('num_imputer',  num_imputer,  num_features)\n",
    "])\n",
    "\n",
    "filled_X = imputer.fit_transform(X)\n",
    "filled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_filled = pd.DataFrame(filled_X, columns=['Make', 'Colour', 'Doors', 'Odometer (KM)'])\n",
    "print(car_sales_filled.head(5), '\\n')\n",
    "print(car_sales_filled.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Make', 'Colour', 'Doors']\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(  'one_hot',\n",
    "                                    one_hot,\n",
    "                                    categorical_features)],\n",
    "                                remainder='passthrough')\n",
    "\n",
    "transformed_X = transformer.fit_transform(car_sales_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing The Right Model For Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.DataFrame(housing['data'], columns=housing['feature_names'])\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df['target'] = housing['target']\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = housing_df.drop('target', axis=1)\n",
    "y = housing_df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = Ridge()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = housing_df.drop('target', axis=1)\n",
    "x = housing_df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease = pd.read_csv(r'C:\\Users\\Doan Trong Hieu\\Downloads\\IMPORTANT\\SPECIALIZATION\\AI\\MACHINE-LEARNING\\CODE_ML\\UDM_ZTM_ML\\data\\heart-disease.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop('target', axis=1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = LinearSVC(max_iter=10000)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop('target', axis=1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting A Model To The Data\n",
    "# Making Predictions With Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.predict(X_test), '\\n')\n",
    "print(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict(X_test)\n",
    "print(np.mean(y_preds == y_test))\n",
    "print(accuracy_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict() vs predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = housing_df.drop('target', axis=1)\n",
    "y = housing_df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_preds[:10], len(y_preds), '\\n')\n",
    "print(np.array(y_test[:10]), len(y_test), '\\n')\n",
    "print(mean_absolute_error(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating A Machine Learning Model (Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop('target', axis=1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_train, y_train), '\\n')\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = housing_df.drop('target', axis=1)\n",
    "y = housing_df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_train, y_train), '\\n')\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop('target', axis=1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_test, y_test), '\\n')\n",
    "print(cross_val_score(clf, X, y, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_single_score = clf.score(X_test, y_test)\n",
    "clf_cross_val_score = np.mean(cross_val_score(clf, X, y, cv=5))\n",
    "\n",
    "print(clf_single_score)\n",
    "print(clf_cross_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop('target', axis=1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "cross_val_score = cross_val_score(clf, X, y, cv=5)\n",
    "print(f'Heart Disease Classifier Accuracy: {np.mean(cross_val_score) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "y_probs_positive = y_probs[:, 1]\n",
    "\n",
    "print(y_probs[:5], y_probs.shape, '\\n')\n",
    "print(y_probs_positive[:5], y_probs_positive.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs_positive)\n",
    "\n",
    "fpr, tpr, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr):\n",
    "    \"\"\"\n",
    "    - Plots a ROC curve given the False Positive rate (fpr) and True Positive rate (tpr)\n",
    "    of a model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    \n",
    "    # Plot line with no predictive power (baseline)\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--', label='Guessing')\n",
    "    \n",
    "    # Plot perfect ROC curve\n",
    "    plt.plot([0, 0], [0, 1], color='r', linestyle='--')\n",
    "    plt.plot([0, 1], [1, 1], color='r', linestyle='--')\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.xlabel('False Positive Rate (fpr)')\n",
    "    plt.ylabel('True Postitive Rate (tpr)')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_probs_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_test, y_preds, rownames=['Actual Labels'], colnames=['Precicted Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(estimator=clf, X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_true=y_test, y_pred=y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating A Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = housing_df.drop('target', axis=1)\n",
    "y = housing_df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Fill an array with y_test mean\n",
    "y_test_mean = np.full(shape=len(y_test), fill_value=y_test.mean())\n",
    "\n",
    "print(r2_score(y_true=y_test, y_pred=y_test_mean), '\\n')\n",
    "print(r2_score(y_true=y_test, y_pred=y_test), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_preds)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_preds, '\\n')\n",
    "print(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={'Actual values':    y_test,\n",
    "                        'Predicted values': y_preds})\n",
    "df['Difference'] = df['Predicted values'] - df['Actual values']\n",
    "print(np.mean(np.absolute(df['Difference'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_preds)\n",
    "df['Squared Difference'] = np.square(df['Difference'])\n",
    "squared = np.mean(np.square(df['Difference']))\n",
    "\n",
    "print(mse, '\\n')\n",
    "print(df.head(), '\\n')\n",
    "print(squared, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation and Scoring Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop('target', axis=1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "cv_acc = cross_val_score(clf, X, y, cv=5, scoring=None)\n",
    "\n",
    "print(cv_acc)\n",
    "print(f'The cross-validated accuracy is: {np.mean(cv_acc) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "cv_acc = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "print(cv_acc)\n",
    "print(f'The cross-validated accuracy is: {np.mean(cv_acc) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "cv_precision = cross_val_score(clf, X, y, cv=5, scoring='precision')\n",
    "\n",
    "print(cv_precision)\n",
    "print(f'The cross-validated precision is: {np.mean(cv_precision) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "cv_recall = cross_val_score(clf, X, y, cv=5, scoring='recall')\n",
    "\n",
    "print(cv_recall)\n",
    "print(f'The cross-validated recall is: {np.mean(cv_recall) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = housing_df.drop('target', axis=1)\n",
    "y = housing_df['target']\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "cv_r2 = cross_val_score(model, X, y, cv=3, scoring=None)\n",
    "print(np.round(cv_r2, 3))\n",
    "print(f'The cross-validated r2 is: {np.mean(cv_r2):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mae = cross_val_score(model, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "print(np.round(cv_mae, 3))\n",
    "print(f'The cross-validated mae is: {np.mean(cv_mae):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mse = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(np.round(cv_mse, 3))\n",
    "print(f'The cross-validated mse is: {np.mean(cv_mse):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating A Model With Scikit-learn Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop('target', axis=1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "print('Classifier metrics on the test set')\n",
    "print(f'Accuracy:  {accuracy_score(y_test, y_preds)  * 100:.2f}%')\n",
    "print(f'Precision: {precision_score(y_test, y_preds):.2f}')\n",
    "print(f'Recall:    {recall_score(y_test, y_preds)   :.2f}')\n",
    "print(f'F1:        {f1_score(y_test, y_preds)       :.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "X = housing_df.drop('target', axis=1)\n",
    "y = housing_df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "print('Regression metrics on the test set')\n",
    "print(f'R2 score: {r2_score(y_test, y_preds):.3f}')\n",
    "print(f'     MAE: {mean_absolute_error(y_test, y_preds):.3f}')\n",
    "print(f'     MSE: {mean_squared_error(y_test, y_preds):.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    - Performs evaluation comparison on y_true labels vs. y_preds labels on a\n",
    "    classification.\n",
    "    \"\"\"\n",
    "    \n",
    "    accuracy    = accuracy_score(y_true, y_preds)\n",
    "    precision   = precision_score(y_true, y_preds)\n",
    "    recall      = recall_score(y_true, y_preds)\n",
    "    f1          = f1_score(y_true, y_preds)\n",
    "    metric_dict = { 'Accuracy':  round(accuracy, 2),\n",
    "                    'Precision': round(precision, 2),\n",
    "                    'Recall':    round(recall, 2),\n",
    "                    'F1':        round(f1, 2)   }\n",
    "    \n",
    "    print(f' Accuracy: {accuracy * 100:.2f}%')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'   Recall: {recall:.2f}')\n",
    "    print(f' F1 score: {f1:.2f}')\n",
    "    \n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "heart_disease_shuffled = heart_disease.sample(frac=1)\n",
    "\n",
    "X = heart_disease_shuffled.drop('target', axis=1)\n",
    "y = heart_disease_shuffled['target']\n",
    "\n",
    "train_split = round(0.7 * len(heart_disease_shuffled))\n",
    "valid_split = round(train_split + 0.15 * len(heart_disease_shuffled))\n",
    "\n",
    "X_train, y_train = X[:train_split],            y[:train_split]\n",
    "X_valid, y_valid = X[train_split:valid_split], y[train_split:valid_split]\n",
    "X_test,  y_test  = X[valid_split:],            y[valid_split:]\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_preds = clf.predict(X_valid)\n",
    "baseline_metrics = evaluate_preds(y_valid, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_2 = RandomForestClassifier(n_estimators=100)\n",
    "clf_2.fit(X_train, y_train)\n",
    "y_preds_2 = clf_2.predict(X_valid)\n",
    "baseline_metrics_2 = evaluate_preds(y_valid, y_preds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "grid = {'n_estimators':      [10, 100, 200, 500, 1000, 1200],\n",
    "        'max_depth':         [None, 5, 10, 20, 30],\n",
    "        'max_features':      ['auto', 'sqrt'],\n",
    "        'min_samples_split': [2, 4, 6],\n",
    "        'min_samples_leaf':  [1, 2, 4]}\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease_shuffled.drop('target', axis=1)\n",
    "y = heart_disease_shuffled['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "rs_clf = RandomizedSearchCV(    estimator=clf, \n",
    "                                param_distributions=grid, \n",
    "                                n_iter=10, \n",
    "                                cv=5,\n",
    "                                verbose=2       )\n",
    "\n",
    "rs_clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_y_preds = rs_clf.predict(X_test)\n",
    "rs_metrics = evaluate_preds(y_test, rs_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_2 = {  'n_estimators':      [100, 200, 500],\n",
    "            'max_depth':         [None],\n",
    "            'max_features':      ['auto', 'sqrt'],\n",
    "            'min_samples_split': [6],\n",
    "            'min_samples_leaf':  [1, 2]  }\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease_shuffled.drop('target', axis=1)\n",
    "y = heart_disease_shuffled['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "gs_clf = GridSearchCV(  estimator=clf, \n",
    "                        param_grid=grid_2, \n",
    "                        cv=5,\n",
    "                        verbose=2   )\n",
    "\n",
    "gs_clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_y_preds = gs_clf.predict(X_test)\n",
    "gs_metrics = evaluate_preds(y_test, gs_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_metrics = pd.DataFrame({'baseline': baseline_metrics,\n",
    "                                'clf_2': baseline_metrics_2,\n",
    "                                'random search': rs_metrics,\n",
    "                                'grid search': gs_metrics})\n",
    "compare_metrics.plot.bar(figsize=(22, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving And Loading A Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\Doan Trong Hieu\\Downloads\\IMPORTANT\\SPECIALIZATION\\AI\\MACHINE-LEARNING\\CODE_ML\\UDM_ZTM_ML\\data\\car-sales-extended.csv')\n",
    "\n",
    "print(data.head(), '\\n')\n",
    "print(data.dtypes, '\\n')\n",
    "print(data.isna().sum(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "data = pd.read_csv(r'C:\\Users\\Doan Trong Hieu\\Downloads\\IMPORTANT\\SPECIALIZATION\\AI\\MACHINE-LEARNING\\CODE_ML\\UDM_ZTM_ML\\data\\car-sales-extended-missing-data.csv')\n",
    "data.dropna(subset=['Price'], inplace=True)\n",
    "\n",
    "categorical_features = ['Make', 'Colour']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "door_feature = ['Doors']\n",
    "door_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=4))\n",
    "])\n",
    "\n",
    "num_features = ['Odometer (KM)']\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat',  categorical_transformer, categorical_features),\n",
    "        ('door', door_transformer,        door_feature),\n",
    "        ('num',  num_transformer,         num_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', RandomForestRegressor())\n",
    "    ]\n",
    ")\n",
    "\n",
    "X = data.drop('Price', axis=1)\n",
    "y = data['Price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_grid = {   'preprocessor__num__imputer__strategy': ['mean', 'meadian'],\n",
    "                'model__n_estimators':                  [100, 1000],\n",
    "                'model__max_depth':                     [None, 5],\n",
    "                'model__max_features':                  ['auto'],\n",
    "                'model__min_samples_split':             [2, 4]  }\n",
    "gs_model = GridSearchCV(estimator=model, param_grid=pipe_grid, cv=5, verbose=2)\n",
    "gs_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
