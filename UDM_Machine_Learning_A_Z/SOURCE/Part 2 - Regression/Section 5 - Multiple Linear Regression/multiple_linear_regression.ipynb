{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CazISR8X_HUG"},"source":["# Multiple Linear Regression"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pOyqYHTk_Q57"},"source":["# Importing the libraries"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{},"colab_type":"code","id":"N-qiINBQSK2g"},"outputs":[],"source":["# Working with array\n","import numpy as np\n","# Plotting chart, graph\n","import matplotlib.pyplot as plt\n","# Import dataset. Create the matrix of features and the dependent variable vector.\n","# Preprocess dataset\n","import pandas as pd\n","# Process missing data\n","from sklearn.impute import SimpleImputer\n","# One hot encoding\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import LabelEncoder\n","# Splitting\n","from sklearn.model_selection import train_test_split\n","# Feature Scaling\n","from sklearn.preprocessing import StandardScaler\n","\n","# Display any numerical value with only 02 decimals afer comma\n","np.set_printoptions(precision=1)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RopL7tUZSQkT"},"source":["# Importing the dataset\n","- Create Data Frame\n","- Create Matrix of features & Dependent variable vector\n","    - Matrix of features: Independent variable. The variables containing some informations with which you can predict what you want to predict. The columns with which you're going to predict the dependent variable.\n","    - Dependent variable vector: The last column of dataset."]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[],"source":["# Create Data frame\n","data_set = pd.read_csv('50_Startups.csv')\n","\n","# Matrix of Features, all the columns of the dataset except the last one\n","# iloc: Locate indexes, take the indexes of the column we want to extract from the dataset, we can get all the rows\n","# Select all rows, take all the columns except the last one\n","# ':': Taking every in the range, this case all the rows\n","# ':-1': Take the indexes from 0 to -1 (Excluding the last index)\n","# `value`: Taking the values\n","X = data_set.iloc[:, :-1].values\n","\n","# Dependent variable vector (The last column of the dataset)\n","# `-1`: Get the last column\n","y = data_set.iloc[:, -1].values"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X:\n","[[165349.2 136897.8 471784.1 'New York']\n"," [162597.7 151377.59 443898.53 'California']\n"," [153441.51 101145.55 407934.54 'Florida']\n"," [144372.41 118671.85 383199.62 'New York']\n"," [142107.34 91391.77 366168.42 'Florida']\n"," [131876.9 99814.71 362861.36 'New York']\n"," [134615.46 147198.87 127716.82 'California']\n"," [130298.13 145530.06 323876.68 'Florida']\n"," [120542.52 148718.95 311613.29 'New York']\n"," [123334.88 108679.17 304981.62 'California']\n"," [101913.08 110594.11 229160.95 'Florida']\n"," [100671.96 91790.61 249744.55 'California']\n"," [93863.75 127320.38 249839.44 'Florida']\n"," [91992.39 135495.07 252664.93 'California']\n"," [119943.24 156547.42 256512.92 'Florida']\n"," [114523.61 122616.84 261776.23 'New York']\n"," [78013.11 121597.55 264346.06 'California']\n"," [94657.16 145077.58 282574.31 'New York']\n"," [91749.16 114175.79 294919.57 'Florida']\n"," [86419.7 153514.11 0.0 'New York']\n"," [76253.86 113867.3 298664.47 'California']\n"," [78389.47 153773.43 299737.29 'New York']\n"," [73994.56 122782.75 303319.26 'Florida']\n"," [67532.53 105751.03 304768.73 'Florida']\n"," [77044.01 99281.34 140574.81 'New York']\n"," [64664.71 139553.16 137962.62 'California']\n"," [75328.87 144135.98 134050.07 'Florida']\n"," [72107.6 127864.55 353183.81 'New York']\n"," [66051.52 182645.56 118148.2 'Florida']\n"," [65605.48 153032.06 107138.38 'New York']\n"," [61994.48 115641.28 91131.24 'Florida']\n"," [61136.38 152701.92 88218.23 'New York']\n"," [63408.86 129219.61 46085.25 'California']\n"," [55493.95 103057.49 214634.81 'Florida']\n"," [46426.07 157693.92 210797.67 'California']\n"," [46014.02 85047.44 205517.64 'New York']\n"," [28663.76 127056.21 201126.82 'Florida']\n"," [44069.95 51283.14 197029.42 'California']\n"," [20229.59 65947.93 185265.1 'New York']\n"," [38558.51 82982.09 174999.3 'California']\n"," [28754.33 118546.05 172795.67 'California']\n"," [27892.92 84710.77 164470.71 'Florida']\n"," [23640.93 96189.63 148001.11 'California']\n"," [15505.73 127382.3 35534.17 'New York']\n"," [22177.74 154806.14 28334.72 'California']\n"," [1000.23 124153.04 1903.93 'New York']\n"," [1315.46 115816.21 297114.46 'Florida']\n"," [0.0 135426.92 0.0 'California']\n"," [542.05 51743.15 0.0 'New York']\n"," [0.0 116983.8 45173.06 'California']]\n","-----------------------------------------------------------------\n","Y:\n","[192261.8 191792.1 191050.4 182902.  166187.9 156991.1 156122.5 155752.6\n"," 152211.8 149760.  146122.  144259.4 141585.5 134307.4 132602.6 129917.\n"," 126992.9 125370.4 124266.9 122776.9 118474.  111313.  110352.2 108734.\n"," 108552.  107404.3 105733.5 105008.3 103282.4 101004.6  99937.6  97483.6\n","  97427.8  96778.9  96712.8  96479.5  90708.2  89949.1  81229.1  81005.8\n","  78239.9  77798.8  71498.5  69759.   65200.3  64926.1  49490.8  42559.7\n","  35673.4  14681.4]\n"]}],"source":["print(f'X:\\n{X}')\n","print('-----------------------------------------------------------------')\n","print(f'Y:\\n{y}')"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CriG6VzVSjcK"},"source":["# Encoding categorical data (One hot encoding\n","- We must turn (`encode`) the `string` categories into `number`\n","- One hot encoding: Creating Binary vector (Only 0 and 1), avoid numerical order\n","- The more categories, the more columns"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AhSpdQWeSsFh"},"source":["## Encoding the Independent Variable"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[],"source":["# Create an object of the Column Transformer class\n","# Arguments: Kind of transformation, indexes of the column we want to transform, the columns we want to keep\n","# `passthrough`: Keep the columns that won't be applied transformation\n","column_transformer = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\n","\n","# Return the new matrix of features that one hot encoded\n","# We update the current matrix of features\n","# The method doesn't return a numpy array -> Force the output of this method to be numpy array\n","X = np.array(column_transformer.fit_transform(X=X))"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.0 0.0 1.0 165349.2 136897.8 471784.1]\n"," [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n"," [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n"," [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n"," [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n"," [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n"," [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n"," [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n"," [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n"," [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n"," [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n"," [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n"," [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n"," [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n"," [0.0 1.0 0.0 119943.24 156547.42 256512.92]\n"," [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n"," [1.0 0.0 0.0 78013.11 121597.55 264346.06]\n"," [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n"," [0.0 1.0 0.0 91749.16 114175.79 294919.57]\n"," [0.0 0.0 1.0 86419.7 153514.11 0.0]\n"," [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n"," [0.0 0.0 1.0 78389.47 153773.43 299737.29]\n"," [0.0 1.0 0.0 73994.56 122782.75 303319.26]\n"," [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n"," [0.0 0.0 1.0 77044.01 99281.34 140574.81]\n"," [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n"," [0.0 1.0 0.0 75328.87 144135.98 134050.07]\n"," [0.0 0.0 1.0 72107.6 127864.55 353183.81]\n"," [0.0 1.0 0.0 66051.52 182645.56 118148.2]\n"," [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n"," [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n"," [0.0 0.0 1.0 61136.38 152701.92 88218.23]\n"," [1.0 0.0 0.0 63408.86 129219.61 46085.25]\n"," [0.0 1.0 0.0 55493.95 103057.49 214634.81]\n"," [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n"," [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n"," [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n"," [1.0 0.0 0.0 44069.95 51283.14 197029.42]\n"," [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n"," [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n"," [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n"," [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n"," [1.0 0.0 0.0 23640.93 96189.63 148001.11]\n"," [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n"," [1.0 0.0 0.0 22177.74 154806.14 28334.72]\n"," [0.0 0.0 1.0 1000.23 124153.04 1903.93]\n"," [0.0 1.0 0.0 1315.46 115816.21 297114.46]\n"," [1.0 0.0 0.0 0.0 135426.92 0.0]\n"," [0.0 0.0 1.0 542.05 51743.15 0.0]\n"," [1.0 0.0 0.0 0.0 116983.8 45173.06]]\n"]}],"source":["print(X)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qb_vcgm3qZKW"},"source":["# Splitting (random) the dataset into the Training set and Test set\n","- Training set: Train ML model on existing observations. -> More data than test set (80%) -> Give the model more chance to understand and learn the correlations in the dataset.\n","- Test set: Evaluate the performance of the model on new observations (future data).\n","- Four parts:\n","    - X_train, X_test: Matrix of features\n","    - y_train, y_test: Dependent variable\n","- Why? The ML model expecting all of 04 parts as input\n","    - Training: X_train, y_train -> fit method\n","    - Prediction|Inference: X_test, y_test -> predict method"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train\n","[[1.0 0.0 0.0 63408.86 129219.61 46085.25]\n"," [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n"," [0.0 0.0 1.0 78389.47 153773.43 299737.29]\n"," [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n"," [0.0 0.0 1.0 86419.7 153514.11 0.0]\n"," [1.0 0.0 0.0 23640.93 96189.63 148001.11]\n"," [1.0 0.0 0.0 0.0 116983.8 45173.06]\n"," [0.0 1.0 0.0 75328.87 144135.98 134050.07]\n"," [0.0 1.0 0.0 73994.56 122782.75 303319.26]\n"," [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n"," [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n"," [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n"," [0.0 0.0 1.0 1000.23 124153.04 1903.93]\n"," [0.0 0.0 1.0 77044.01 99281.34 140574.81]\n"," [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n"," [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n"," [0.0 1.0 0.0 55493.95 103057.49 214634.81]\n"," [0.0 1.0 0.0 119943.24 156547.42 256512.92]\n"," [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n"," [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n"," [0.0 1.0 0.0 66051.52 182645.56 118148.2]\n"," [1.0 0.0 0.0 22177.74 154806.14 28334.72]\n"," [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n"," [0.0 1.0 0.0 91749.16 114175.79 294919.57]\n"," [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n"," [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n"," [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n"," [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n"," [1.0 0.0 0.0 0.0 135426.92 0.0]\n"," [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n"," [1.0 0.0 0.0 78013.11 121597.55 264346.06]\n"," [0.0 0.0 1.0 165349.2 136897.8 471784.1]\n"," [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n"," [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n"," [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n"," [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n"," [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n"," [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n"," [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n"," [1.0 0.0 0.0 44069.95 51283.14 197029.42]]\n","----------------------------------------------\n","X_test\n","[[0.0 0.0 1.0 72107.6 127864.55 353183.81]\n"," [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n"," [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n"," [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n"," [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n"," [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n"," [0.0 0.0 1.0 542.05 51743.15 0.0]\n"," [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n"," [0.0 1.0 0.0 1315.46 115816.21 297114.46]\n"," [0.0 0.0 1.0 61136.38 152701.92 88218.23]]\n","----------------------------------------------\n","y_train\n","[ 97427.8  81005.8 111313.   90708.2 122776.9  71498.5  14681.4 105733.5\n"," 110352.2 134307.4  77798.8 125370.4  64926.1 108552.  108734.  166187.9\n","  96778.9 132602.6  99937.6 146122.  103282.4  65200.3  96712.8 124266.9\n"," 118474.  107404.3 156122.5 155752.6  42559.7 191792.1 126992.9 192261.8\n"," 129917.  156991.1 144259.4 149760.  152211.8 141585.5  69759.   89949.1]\n","----------------------------------------------\n","y_test\n","[105008.3  96479.5  78239.9  81229.1 191050.4 182902.   35673.4 101004.6\n","  49490.8  97483.6]\n"]}],"source":["print(f'X_train\\n{X_train}')\n","print('----------------------------------------------')\n","print(f'X_test\\n{X_test}')\n","print('----------------------------------------------')\n","print(f'y_train\\n{y_train}')\n","print('----------------------------------------------')\n","print(f'y_test\\n{y_test}')"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"k-McZVsQBINc"},"source":["# Training the Multiple Linear Regression model on the Training set\n","- The class will automatically avoid `Dummy variable trap`"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training model ...\n","Training completed!\n"]}],"source":["from sklearn.linear_model import LinearRegression\n","\n","regressor = LinearRegression()\n","\n","# Train the model\n","print('Training model ...')\n","regressor.fit(X=X_train, y=y_train)\n","print('Training completed!')"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xNkXL1YQBiBT"},"source":["# Predicting the Test set results"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["y_test\n","[105008.3  96479.5  78239.9  81229.1 191050.4 182902.   35673.4 101004.6\n","  49490.8  97483.6]\n","\n","-----------------------------------------------------------------\n","y_predicted\n","[114664.4  90593.2  75692.8  70221.9 179790.3 171576.9  49753.6 102276.7\n","  58649.4  98272. ]\n","\n","-----------------------------------------------------------------\n","[[114664.4 105008.3]\n"," [ 90593.2  96479.5]\n"," [ 75692.8  78239.9]\n"," [ 70221.9  81229.1]\n"," [179790.3 191050.4]\n"," [171576.9 182902. ]\n"," [ 49753.6  35673.4]\n"," [102276.7 101004.6]\n"," [ 58649.4  49490.8]\n"," [ 98272.   97483.6]]\n"]}],"source":["# Get vector of predictions | The predicted value of the model for the test set | Input the features of test set\n","y_predicted = regressor.predict(X=X_test)\n","\n","print(f'y_test\\n{y_test}\\n')\n","print('-----------------------------------------------------------------')\n","print(f'y_predicted\\n{y_predicted}\\n')\n","print('-----------------------------------------------------------------')\n","\n","# Display the real values and the predicted values together\n","# reshape(len(y_predicted), 1) -> Turn into the vertical vector\n","# axis=1 -> Concatenate horizontally 02 vertical vectors of `y`\n","print(np.concatenate((y_predicted.reshape(len(y_predicted), 1), y_test.reshape(len(y_test), 1)), axis=1))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPhYhte6t7H4wEK4xPpDWT7","name":"Multiple Linear Regression","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
